<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Codematician]]></title>
  <link href="http://andy.terrel.us/atom.xml" rel="self"/>
  <link href="http://andy.terrel.us/"/>
  <updated>2012-11-01T10:30:49-05:00</updated>
  <id>http://andy.terrel.us/</id>
  <author>
    <name><![CDATA[Andy R. Terrel]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Rule of Software: Usabilty]]></title>
    <link href="http://andy.terrel.us/blog/2012/11/01/a-rule-of-software-usability/"/>
    <updated>2012-11-01T10:00:00-05:00</updated>
    <id>http://andy.terrel.us/blog/2012/11/01/a-rule-of-software-usability</id>
    <content type="html"><![CDATA[<p>Make your software useful.  That is the point without usefulness there is no
need for existence.</p>

<p>If you write a function that is not useful, scrub it from your text editors
as not to offend the blessed pixels. Do not fear throwing away non-useful parts
of your code, better to cast away these parts rather than sacrifice the
usefulness of the whole.</p>

<p>If it is useful to repeat yourself, do so.  Repeating yourself in subtly
different ways teaches your novices, which must be done well. If there is a
common pattern for your task use it, until it is not useful anymore. Write your
tests as soon as they will be useful, tests are always useful before giving
your code to others. Separate your code into useful partitions. If the
partitions are too big or too small the usefulness will be clouded as it is
difficult to track the function and interplay between the partitions.</p>

<p>When the program is done, let it stand on its usefulness.  If others do not
find it useful, seek out more to judge your craft. If none count themselves
blessed to have witnessed your skill, throw out the program. Better had the
program not been born than to prop it up with false claims of usefulness or
many words about its beauty, adherence to principles, or features that none
have found useful.</p>

<p>Each programmer must look from within to find the metric of usefulness.
Some programs are only useful to the programmer, others must be useful to a
multiplicity of programmers, and few hold themselves to such high esteem as
being useful to the unwashed non-programming masses.  Do not make the program
raise malcontent by seeking affection in those it cannot help.</p>

<p>The API can hold back the usefulness of your code. Write many useful programs
with the API and minimize their length.  Large APIs are weaker than small APIs,
but both can be useful.  Do not be afraid to erase parts of the API which were
only scaffolding to find the better API, the masterpiece could not have been
made without the scaffolding, but if it is left standing it will obstruct.</p>

<p>When the performance guru tells you speed is more important, ask them why they
don&#8217;t make their users write in assembly, why BLAS doesn&#8217;t require you to pack
your own matrices, and why the CMS doesn&#8217;t make you connect to your own
sockets. To discourage performance hacks give the programmer five lashes as
these hacks are the enemy of abstraction, which can be useful. If the
programmer persist in their hacks, let them continue as clearly the speed is
useful.</p>

<p>When the enterprise architect recommends yet another abstract factory
manager class, ask them why they started programming and at what point they
decided to make others despise reading their code.  Separate them from the
strong, eager, useful programmers and burn their resumes so that others do not
confuse their ways as useful.</p>

<p>If the functional zealot tells you your side effects destroy the formal
analysis, explain to him that monads rhymes with gonads which are quite
useful. Ask them to travel discalced to the far reaches of the empty quarter so
they do not harm useful programmers ears.  Remember these prophets ramblings as
even they are sometimes useful. Teach them to the young, but always remind them
of the first rule.</p>

<p>When your sales representative tells you to remove the useful parts of your
code, give them wind and ask them to sell the liberated air.  When your project
manager wants features that are not useful, give them a shovel and ask them to
remove dirt from the parched earth only to have them place it back again for
they have forgotten the first rule and should be left to sisyphean
tasks. When other programmers check in code that is not useful, give them the
rule and ask them if they are on the path to manager or guru.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Packaging]]></title>
    <link href="http://andy.terrel.us/blog/2012/10/28/python-packaging/"/>
    <updated>2012-10-28T20:08:00-05:00</updated>
    <id>http://andy.terrel.us/blog/2012/10/28/python-packaging</id>
    <content type="html"><![CDATA[<p>There are two major hurdles to Python disrupting the entire HPC work stack:
packaging and <a href="http://pyvideo.org/video/1201/solving-the-import-problem-scalable-dynamic-load">dynamic loading</a>. Today I want to discuss the packaging issue.
While there are many people working on these hurdles, it is my opinion that the
community needs to seek out methods to solve these hurdles together in a
satisfactory way. I see this problem taking shape in many different
communities, but the HPC version of the problem is probably the most difficult,
thus by solving it, we can provide solutions for many other communities as well.</p>

<p>To this end, I helped host a conference call among the young, enthusiastic
<a href="http://numfocus.org/">NumFOCUS</a> community.  This call seemed much more of a
get to know the problem rather than a listing of solutions.  We are working on
editting the call and hope to have it published as a
<a href="http://www.inscight.org">InSCIght</a> podcast soon.  The call included several
companies that produces packaged Python solutions, university folks from around
the globe, and industrial users of Python.  The interest in the call was so
great that we had to switch mediums at the last moment and lost out on some
interactions with other great folks.  I hope to have another call in the future
and a discussion at the upcoming <a href="http://sc12.supercomputing.org/schedule/event_detail.php?evid=bof154">SuperComputing 2012 conference</a>.</p>

<h2>What is wrong with Python Packaging</h2>

<p>Perhaps the place to start is defining the problem.  When you have a piece of
code in a pure Python setting, one easily adds the top source directory to
<code>PYTHONPATH</code> and happily imports away.  This model works quite well
usually. For the first years of Google App engine, code could only be installed
in this manner.</p>

<p>The issue is that in HPC one must depend upon libraries that are highly tuned
for specifics of the architecture where the code is run.  These highly tuned
libraries often include assembly and usually only include compiled static or
shared libraries.  Since, HPC often uses specific compilers dedicated to their
hardware, these libraries depend on the formats compatible with those
compilers.  To further enhance the problem, if these libraries are distributed
via MPI, then the libraries depend on the MPI implementation (which depends
upon the compiler).  At TACC we have a hierarchical module system to keep this
all straight.  You load the compiler, then the MPI implementation, and finally
any libraries.  If you switch to a different compiler, the entire stack is
reloaded.  Actually a big part of my job is to make sure these stacks are all
compiled in a way that they can be switched out, something that is a feat with
biology codes. In a nutshell, we have a huge dependency chain that is binary
and machine dependent.</p>

<p>Python isn&#8217;t supporting this long list of dependencies very well.  For HPCers
this is not new as we are use to having to hack build and package systems.  In
fact in the eight years I&#8217;ve been around the FEniCS community, I&#8217;ve seen four
package systems come and go.  It took me three weeks to get the Trilinos code
installed on my system back in 2006, at the time folks opined that picking that
the right Trilinos configure was NP-Hard. It is much better today. In both cases
though, CMake has turned out to be the tool that has stabilized everything.</p>

<p>Why can&#8217;t Python support this jumble of dependencies?  The reasons are many,
but as <a href="https://twitter.com/cournape">David Cournapeau</a> has pointed out, Python
fundamentally mixes both build and packaging together in a way that makes it
impossibly hard.  I don&#8217;t know David&#8217;s history, but he seems pretty critical of
the community about not understanding the issue.  Rather than rehash all the
arguments, I&#8217;m going to outline my view of the solution, separating build and
packaging.</p>

<h2>The build process</h2>

<p>The difficult part of the build process is not calling the compiler, rather
configuring the environment and compiler flags to produce the desired binary.</p>

<p>To give a simple example, if you are compiling a threaded library, say using
OpenMP, you need to know that gcc uses -fopenmp, icc uses -openmp, pgi
-mp, something else on xl, and clang doesn&#8217;t even support it.  Thank you
Apple for making my job that much harder by using a default compiler that
doesn&#8217;t support OpenMP.</p>

<p>Okay that&#8217;s actually not hard to code, but it gets better.  Because multicore
threading is still an infant technology, if you compose several threaded
libraries you can see a real performance degradation (despite
<a href="https://twitter.com/dabeaz">@dbeaz</a> thinking threading is easy). Thus most
vendors provide a threaded version of BLAS and a sequential version, the idea
being if you have a big matrix to work with make BLAS be the multithreaded
portion of the code, but if you have lots of smaller matrices let the
application be multithreaded.  This means that each application could be built
with 4 compilers X 2 BLAS threading modes, we also need to throw in debugging
and optimized modes as yes -O3 versus -g -O0 really do matter.</p>

<p>In this trivial example, we already need to test 16 different builds of a
library, not to mention figuring out how many threads to run (which is often a
runtime decision with OpenMP). If you want to drive your graduate students to
madness get them to install Scalapack on your cluster.</p>

<p>At this point, you might say &#8220;16 versions of the library, quit your crying,
baby!&#8221;. It should be easy to script except Python distribution tools really
don&#8217;t give a way to manage these different compiler flags.  In many cases the
tools just slaps your code in some place on the path and runs all sorts of
bootstrapping patching hacks to install at all.  Virtualenv give a bit of sanity as
one can isolate different Python builds, but it doesn&#8217;t handle any of the
system libraries at all.  It is my understanding that when EPD was built, they
initially tried to fix this problem but quickly switched to a single binary
only distribution model.</p>

<p>To tackle all these burdens, we need to start using real configure and build
tools.  They need to work on all platforms, yes Windows matters in HPC. They
need to be free and open source. And they actually already exist, the community
just needs to start adopting them and that will take some effort.  The two
tools I&#8217;ve seen used well are <a href="http://cournape.github.com/Bento/">Bento</a>
produced by David and <a href="http://www.cmake.org/">CMake</a> produced by Kitware.  I&#8217;m
not going to have a bake-off on the pros and cons of each, I have far more
experience with CMake but people I trust tell me Bento is far easier to use. If
NumFOCUS and the PSF really wants to help the community today, it would start
helping people augment distutils to use one of these tools.</p>

<h2>The package selection process</h2>

<p>Now that we&#8217;ve discussed the build process, we need to package up those builds
and allow developers to use them.  I was really glad the Yaroslav, one of the
Debian developers, and Samuel, homebrew&#8217;s Python guy, was able to join us on
the call.  Open source platforms have created great packaging tools, but it
only gets us code monkeys about halfway.  I can install the basic libraries
that aren&#8217;t cutting edge and don&#8217;t need fine grain configuration system
wide. Then I just keep the jumbled mess in my developer space.  But what if a
developer needs to fix a bug with one of those system installed libraries that
isn&#8217;t the version installed? I&#8217;ve spend more time futzing with the packaging
system installer than fixing the bug.</p>

<p>The truth of the matter is we really want the jumbled mess to be managed better
too.  Just like on my supercomputer, I can issue a single command and have a
whole new compiler stack working, why can&#8217;t I do that with my current
development tree.  Here enters
<a href="https://github.com/hashdist/hashdist/wiki">HashDist</a>.  HashDist is
<a href="http://folk.uio.no/dagss/">Dag</a> and <a href="http://ondrejcertik.com/">Ondrej&#8217;s</a> plan
for fixing this problem.  The idea is to build libraries and stash them some
place, recording the necessary details in a small distribution file that is
hashed and put in a database store.  Now when you need to build different
versions of a library, one can simply refer to the different hashes of the
other built libraries. At this point, HashDist is vaporware that has some
funding.  I have been working with these guys trying to fund this project for
about a year and a half.</p>

<p>Let me be frank.  If this tool existed, reporting bugs could come with a
hashdist number that would set your machine up in the bug state immediately,
i.e., no more futzing with installers just working.  For HPC systems this would
be huge. Hell it is even a good idea for a SAAS startup company.</p>

<p>This is very similar to the module system that we use at TACC, lmod, but it
should build into the development cycle not just running a supercomputer.  For
what its worth, supercomputers use module systems because when you have 5000
users on a machine, you have to keep the kids from stepping on each others
toes.</p>

<h2>Why this affects developers outside of HPC</h2>

<p>Hopefully, I&#8217;ve explained the problem well enough and pointed to a few
promising fixes.  While these problems are accentuated in HPC systems, they
exist everywhere.  Every single company, I have consulted with has this
problem.  They solve it different ways, but they all manage their own build and
packaging system.  Every single open source scientific Python team, has this
problems.  They usually solve it the old fashioned way, indentured servants, err
graduate students.  But perhaps more importantly, as PyPy and other python
distributions threaten CPython for popularity, even Python core is having these
problems. The wheel proposals are a good first step, but its gonna take more
than changing package names to fix it.</p>

<p>NumFOCUS was founded to help encourage businesses and institutions to put
funding together to solve science software problems. This is a big problem and
one that prevents a large number of people from effectively using our
ecosystem.  I would like to see more funds and community resources put forward
to create working solutions. Finally a homework for everyone who has read this
far. I invite you to send me your versions of how you fix Python
packaging for your work so I can collect the best ideas.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thoughts on the SciPy Conference]]></title>
    <link href="http://andy.terrel.us/blog/2012/10/08/thoughts-on-the-scipy-conference/"/>
    <updated>2012-10-08T01:24:00-05:00</updated>
    <id>http://andy.terrel.us/blog/2012/10/08/thoughts-on-the-scipy-conference</id>
    <content type="html"><![CDATA[<p>For SciPy2012 I was given the privilege of serving as the co-chair of the
program committee.  The experience was exciting and rewarding as I was able to
affect what I view as one of the most important conferences for the scientific
world. Now, that&#8217;s a pretty bold statement and I&#8217;m not going to dwell on it
long here, but essentially many conferences people go to show off;
SciPy is a conference where people come to learn best practices.  And when young
scientists are able to see science rock stars like Joshua Bloom lift up the
covers and show off how his scientific process works, it changes their entire
workflow creating more efficient, better scientists. With that said, I would
like to focus more on my opinions about the state of the conference, its
successes and failures, and how I believe the conference should be transformed.</p>

<h2>The state of the SciPy Community</h2>

<p>It was a bit strange being the co-chair of the program committee at SciPy2012,
because prior to 2012 I had only attended one SciPy conference.  Of course, I
have known about the conference for years and have tried to go many times but
life has always gotten in the way.  Additionally, I came to the scientific
Python community after most everything had evolved to a pretty high level of
quality.  Sure there are bits and pieces that could use some polish, but
largely I feel that my contributions have all been cosmetic (although the GSOC
students I have mentored have done phenomenal work). This puts me at a bit of a
disadvantage to extol any long history of the SciPy community, but I&#8217;m sure
someone will let me know where I get things right and wrong.</p>

<p>There are some interesting divides in the community.  For example, SciPy can
refer to many different things:</p>

<ol>
<li>The US SciPy conference,</li>
<li>The international SciPy conference series,</li>
<li>The Python package named scipy,</li>
<li>The basic scientific computing stack used by most pythonistas, and/or</li>
<li>Any piece of code slightly related to science and Python</li>
</ol>


<p>For this article, when I say SciPy I am talking about the US SciPy conference
(since if I usually can&#8217;t afford to make it to SciPy in Austin, TX, I sure
can&#8217;t afford to go to Brussels or India) and a mix of the other topics.  SciPy
was originally a set of friends who got together in a room at Caltech to chat
and hack about the scipy package.  They use to have these talks from the core
devs where each gave a summary of the package and largely discuss technical
issues around these packages.  As of late, the conference has turned into much
more of a place where any scientist or technical computing professional can go
and hear about a very wide variety of topics on science and Python.</p>

<p>This change in community is both a good and a bad thing.  It means that at
coffee, there are a lot of strange faces and let&#8217;s be honest if we were the
most social crowd we wouldn&#8217;t have spent a non-trivial amount of our lives
pouring over code and mathematics.  Second we seem to have lost some of the
core devs attention.  For example, in the months preceding the conference the
numpy mailing list had turned into a pretty nasty flamewar.  At the conference,
I only saw one of the major contributors to the numpy code base.  I find the
fact that SciPy isn&#8217;t the most important event on the calendar for these devs
kind of surprising.  After all this is where you core devs are the gurus
everyone has come to be inspired by.</p>

<p>The good news is that we are able to see a more accurate view of the
penetration of Python in science.  But not only science, pretty much all
technical computing areas of industry, academia, and government were
represented.  The conference had a record number of attendees and submissions,
in fact this was the first SciPy that we knew of where people received
rejections.</p>

<h2>Successes and Failures of SciPy 2012</h2>

<p>In many ways SciPy is a great conference, but in other ways it is lacking.  I
want to explore a few of these ideas, get feedback from the community, and put
the consensus into action.</p>

<h3>Success</h3>

<blockquote><p>If it ain&#8217;t broke don&#8217;t fix it ~ Anonymous</p></blockquote>

<h4>Topics</h4>

<p>The past two years, there have been two special topics.  Last year was Big Data
and Core Issues; this year we did High Performance Computing and Visualization.
The truth was that we picked these topics because a few motivated folks were
excited about them.  This is true about the domain session this year as well.
Lauren and I chatted, I gave names and she went calling people down to get the
right set of talks.  Largely I think this works, but I don&#8217;t like it.</p>

<p>I don&#8217;t like it because the community wasn&#8217;t really involved and when you have
a couple of people picking the overall direction of a community, it largely
becomes a clique.  If we want to keep a vibrant community, I think these topics
are really important as they are aimed at bringing in people from outside our
community.</p>

<p>With that said, my proposal this year would be:</p>

<ul>
<li>Machine Learning, and</li>
<li>Geographic Information Systems</li>
</ul>


<p>Both topics that came out during the surveys and are a broad cutting
technologies.  Machine Learning should be a no-brainer as the Big Data world
needs it more than ever, but GIS is a bit harder for me to predict being a
break out success.  Of course last year I thought HPC would be the small topic
and Vis a bigger draw, but I was dead wrong.  We could of had the whole
conference on PyHPC (if you want sort of thing, check out the SuperComputing
Conference pyHPC workshop).</p>

<h4>Fabulous plenaries</h4>

<p>This year I believe the plenaries were really off the chart.  I was actually
recruited to help out after the plenaries had already been chosen, so this was
really Stéfan and Warren&#8217;s doing.  I really like the format as well. A talk
about a well-known package, a science talk about the things people are able to
accomplish with the tools, and a look into industry and how our community
relates.</p>

<p>I have quite a few ideas about how to replicate this formula, but I believe we
should probably have some discussion from the community.</p>

<h4>Poster session</h4>

<p>The poster session was great.  There was a lot of interaction between people at
the session.  I&#8217;m somewhat beside myself on the session though.  I thought it
would be better during the reception, but we couldn&#8217;t get the posters in the
reception room and be visible during the entire conference.  I really liked
the poster session and hope to see it in the future.  One fact of science
conferences is that usually it is harder to get funding if you don&#8217;t have
something to present.  Posters are a great way to increase participation,
although I do wonder if we need to go to three parallel tracks in the future.</p>

<h4>Domain science symposiums</h4>

<p>The symposiums at the end of the day were much sparser than the day.  This was
expected, but they play an important role.  As the main session includes a
large number of folks that have quite different domains, these sessions allowed
for topic specifics to be discussed.  More and more domain conferences are
including sessions on Python, but SciPy allows for sessions to grab the
attention of Python experts who are often able to give fresh advice.</p>

<h3>Failures</h3>

<blockquote><p>Develop success from failures. Discouragement and failure are two of the
surest stepping stones to success.  ~ Dale Carnegie</p></blockquote>

<p>Failure is probably too harsh a word for what I discuss in this section.  It&#8217;s
more adequately, &#8220;Things that disappointed Andy.&#8221;  And as most people who know
me know, I&#8217;m not afraid to tell you why I&#8217;m disappointed (only I usually use
harsher words).  At any rate, I believe in <a href="http://www.admittingfailure.com/">admitting
failure</a> and want to discuss a few things I
would like to rectify.</p>

<h4>Community involvement</h4>

<p>For the most part, the conference is put on by about four people.  Sure there is
a longer list on the website, but the brunt of the work falls on a few.  I
would like to see this change.  For example, look at how PyCon is run.  There
are more volunteers than you can count. While Enthought is an amazing
institutional sponsor of the event, they only have a small number of resources
to put into the event.  My impression is that these resources are over
exhausted.</p>

<p>It is time we as a community come together to setup structures for more
community participation.  For example, the websites need work, the process of
reviewing papers needs work, there needs to be more logistical help at the
meeting, and so on.  My guess is that most people don&#8217;t even know that they
could be helping. To even start though we need to build a volunteer network and
appropriate web presence to give volunteers things to do.</p>

<h4>Diversity</h4>

<p>Matt Davis brought this up on Twitter, but I want to echo it louder.  There was
a discouraging lack of diversity at SciPy.  I believe there were 100 males to
every female and very few minorities.  When talking to a few people about this,
the general view was that there just aren&#8217;t women coders around.  I think this is
really wrong, I think that women coders either don&#8217;t know about SciPy or don&#8217;t
care.</p>

<p>Which brings up how do you attract female coders?  One metric given to me is
that conferences with women plenary speakers and/or women on the executive
staff have 50% more women participants.  I look at the places we advertised and
we didn&#8217;t focus on any female or minority organizations.  Closing this gap will
only make our community more vibrant.</p>

<h4>Industry/Academia interactions</h4>

<p>SciPy is a place where there are a few industrial partners but there could be
many more. The problem I saw on the program committee was that anyone who
submitted work on closed source software were negatively impacted.  We are an
open source community but hundreds (thousands?) of companies use our tools.
Industrial partners that come back to the community and talk about how to
interact more can only be a good thing.  For one it will give us a since of the
impact that SciPy has beyond the halls of academia.  It will heighten our
profile among young developers as they are able to come to SciPy to meet
potential employers.</p>

<p>My suggestion here would be to have vendor booths and a recruitment event.  I
would even go as far to suggest hosting a few sponsor speaking sessions.  Open
source is often supported by industry, just as the scipy stack has been
supported by Enthought for years.  Inviting industry to our meeting will make it
more visible.</p>

<h4>Social Media</h4>

<p>The lack of social media at the conference is quite surprising.  Are we all old
fuddies who don&#8217;t know how to use social media to discuss?  It is quite
exciting to go to a conference where the social media around the conference is
working well.  It allows for more dialog among the participants and thus a
greater shared experience.</p>

<p>With that said, I would like to see a greater use of Twitter, G+ and Facebook
throughout the event, including planning. Connecting our community may even
heal all those fights we have on mailing lists.</p>

<h4>Lack of Core Developers</h4>

<p>I&#8217;ve already touched on this, but one last failure is the lack of core project
developers at the conference.  Sure people have lots competing with their time,
but this is the conference dedicated to the code we spend so much free time
on.  Conversations at SciPy are still having an effect on the directions of
codes (in fact today scipy.users had a long conversation about the scipy domain which
was hotly discussed at the sprints).</p>

<p>The few ideas I have on bringing the coders back include:</p>

<ol>
<li>More sprinting (space every night <em>all night</em>)</li>
<li>Sessions dedicated to core projects</li>
<li>More organization around BoFs</li>
<li>Conference sponsorship for devs to attend conference</li>
</ol>


<h2>Vision</h2>

<p>Okay 2000 words in and I&#8217;m sure you are getting bored.  But I&#8217;ve said this
before and I&#8217;ll say it again.  There is no reason SciPy shouldn&#8217;t be as large
as PyCon.  While there are certainly more users of the Python language, our
community is always one of the featured groups when Python users are
discussed.  The suggestions I outlined above are only a small set of comments I
really have, but they are the ones I feel probably need a broader discussion.</p>

<p>For me the vision of SciPy should be simple.  SciPy is the fuel of the
scientific Python movement.  It is where producers and consumers of
scientific and technical code come to learn from each other and make each other
better scientists and coders.  SciPy as a conference should be inclusive of all
technical disciplines and help mentor novice programmers. Finally, it should be
the place where we inject new life into our projects, hack the wild ideas we
only dream about, and submit pull requests that change the face of science.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting started with Python in HPC]]></title>
    <link href="http://andy.terrel.us/blog/2012/09/27/starting-with-python/"/>
    <updated>2012-09-27T15:57:00-05:00</updated>
    <id>http://andy.terrel.us/blog/2012/09/27/starting-with-python</id>
    <content type="html"><![CDATA[<p>Getting to know Python is a pretty hairy task, as is diving into any language.  Fortunately Python is considered an easy language to learn and the potential for using it in HPC settings is pretty large.  Below I give an introduction to learning, speeding, and scaling Python.  Each topic can be the subject of its own book, so take these talking points and notes as only hints to what one can look at.  For a very detailed view of this topic for scientists I recommend the following three books:</p>

<ul>
<li><strong><a href="http://www.springer.com/mathematics/computational+science+%26+engineering/book/978-3-642-30292-3">A Primer on Scientific Programming with Python</a></strong></li>
<li><strong><a href="http://www.springer.com/mathematics/computational+science+%26+engineering/book/978-3-540-73915-9">Python Scripting for Computational Science</a></strong></li>
<li><strong><a href="http://shop.oreilly.com/product/0636920023784.do">Python for Data Analysis</a></strong></li>
</ul>


<h2>Learning Python</h2>

<p>There are a very large number of resources for learning the Python language.  The issue of course is finding a resource that is attractive to the correct mindset.  Very often something that a programmer is able to learn from has little resonance with an artist.  For this reason, I am going to list off a couple of places that I find particularly good, but of course I have been programming for over a decade.</p>

<p>While learning the language is important, the real value of Python is the numerous libraries and the community around the tools.  With that said finding what your particular community is doing is pretty important, but there are a core set of tools that are used by most Pythonistas. I list off a few of these tools for your consumption.</p>

<p>Also, because we like to see what people are doing with Python, I list off a few shining examples of Python in the wide world of scientific computing.  I have to admit that there are a huge number of possibilities but few in the realm of HPC.  At the very least, a HPC person should know Python for its scripting abilities but as the other sections of this document underscore, Python is a good candidate for HPC codes as well.</p>

<h3>Python Tutorials</h3>

<ul>
<li><strong><a href="http://docs.python.org/tutorial/">Python Doc Tutorial</a></strong>: This is the tutorial written by the developers of Python, best for programmers.</li>
<li><strong><a href="http://www.greenteapress.com/thinkpython/">Think Python</a></strong>: A book for non-programmers.</li>
<li><strong><a href="http://scipy-lectures.github.com/">SciPy Lectures</a></strong>: A series of lectures written by scientists geared towards scientists.</li>
<li><strong><a href="http://fperez.org/py4science/starter_kit.html">Py4Science Starter Kit</a></strong>: A version of this page written in 2008.  Lots of good material but a bit less selective.</li>
</ul>


<h3>Python Tools</h3>

<ul>
<li><strong><a href="https://store.continuum.io/cshop/anaconda">Anaconda Pro</a></strong>: A distribution of common Python packages for Big Data and Cluster programming.  Includes disco (a Python map-reduce) and mpi4py which is of more interest to HPCers.</li>
<li><strong><a href="http://www.enthought.com/products/epd.php">Enthought Python Distribution</a></strong>: A distribution of the most commonly used tools by the community (free for academics).</li>
<li><strong><a href="http://numpy.scipy.org/">NumPy</a></strong>:</li>
<li><strong><a href="http://scipy.org">SciPy</a></strong>: A collection of scientific libraries.</li>
<li><strong><a href="http://matplotlib.sourceforge.net/">MatPlotLib</a></strong>: A highly customizable 2D plotting library</li>
<li><strong><a href="http://ipython.org/">IPython</a></strong>: An interactive Python shell and parallel code manager.  The IPython notebook has become very popular and allows users to use an interface similar to Mathematica on a supercomputer.</li>
</ul>


<h3>Python Stories</h3>

<ul>
<li><strong><a href="http://conference.scipy.org/">SciPy Conferences</a></strong>: The series of conferences associated with the scientific Python community see recent videos at <a href="http://pyvideo.org/category/20/scipy_2012">PyVideo</a>.</li>
<li><strong><a href="http://www.youtube.com/watch?v=mLuIB8aW2KA&amp;feature=youtu.be">Python in Astronomy</a></strong>: Joshua Bloom from UC Berkeley gave a keynote talk at SciPy 2012 on &#8220;Python as Super Glue for the Modern Scientific Workflow&#8221;</li>
<li><strong><a href="http://numfocus.org/user-stories/">NumFocus User Stories</a></strong>: A foundation for scientific computing tools with a growing number of user stories.</li>
<li><strong><a href="http://numerics.kaust.edu.sa/papers/pyclaw-sisc/pyclaw-sisc.html">PyCLAW</a></strong>: A petascale application written in Python</li>
</ul>


<h2>Performance</h2>

<p>Despite all the great features outlined above, the (mis)perception is that Python is too slow for HPC Development.  While it is true that Python might not be the best language to write your tight loop and expect a high percentage of peak flop rate, it turns out that Python has a number of tools to help switch to those lower-level languages.</p>

<p>To discuss performance I outline three sets of tools:  profiling, speeding up the Python code via C/Fortran, and speeding up Python via Python.  It is my view that Python has some of the best tools for looking at what your code&#8217;s performance is then drilling down to the actual bottle necks.  Speeding up code without profiling is about like trying to kill a deer with an uzi.</p>

<h3>Python tools for profiling</h3>

<ul>
<li><strong><a href="http://docs.python.org/library/profile.html">profile and cProfile modules</a></strong>: These modules will give you your standard run time analysis and function call stack.  It is pretty nice to save their statistics and using the pstats module you can look at the data in a number of ways.</li>
<li><strong><a href="http://packages.python.org/line_profiler/">kernprof</a></strong>: This tool puts together many routines for doing things like line by line code timing</li>
<li><strong><a href="http://pypi.python.org/pypi/memory_profiler">memory_profiler</a></strong>: This tool produces line by line memory foot print of your code.</li>
<li><strong><a href="http://ipython.org/ipython-doc/dev/interactive/tutorial.html#magic-functions">IPython timers</a></strong>: The <code>timeit</code> function is quite nice for seeing the differences in functions in a quick interactive way.</li>
</ul>


<h3>Speeding up Python</h3>

<ul>
<li><strong><a href="http://cython.org/">Cython</a></strong>: Cython is the quickest way to take a few functions in Python and get faster code.  You can decorate the function with the cython variant of Python and it generates c code.  This is very maintainable and can also link to other hand written code in c/c++/fortran quite easily.  It is by far the preferred tool today.</li>
<li><strong><a href="http://docs.python.org/library/ctypes.html">ctypes</a></strong>: Ctypes will allow you to write your functions in c and then wrap them quickly with its simple decoration of the code.  It handles all the pain of casting from PyObjects and managing the gil to call the c function.</li>
<li><strong><a href="http://fwrap.sourceforge.net/">FWrap</a></strong> and <strong><a href="http://cens.ioc.ee/projects/f2py2e/">f2py</a></strong>: Fortran wrapping tools. FWrap is a newer tool for F90 and integrates with the rest of cython, and f2py is the older more standard tool.  Unfortunately, neither of these libraries are well maintained but are used in numerous projects.</li>
</ul>


<p>Other approaches exist for writing your code in C but they are all somewhat more for taking a C/C++ library and wrapping it in Python.</p>

<h3>Python-only approaches</h3>

<p>If you want to stay inside Python mostly, my advice is to figure out what data you are using and picking correct data types for implementing your algorithms. It has been my experience that you will usually get much farther by optimizing your data structures then any low level c hack. For example:</p>

<ul>
<li><strong><a href="http://numpy.scipy.org/">numpy</a></strong>: A contiguous array very fast for strided operations of arrays</li>
<li><strong><a href="http://code.google.com/p/numexpr/">numexpr</a></strong>: A numpy array expression optimizer.  It allows for multithreading numpy array expressions and also gets rid of the numerous temporaries numpy makes because of restrictions of the Python interpreter.</li>
<li><strong><a href="http://pypi.python.org/pypi/blist">blist</a></strong>: A b-tree implementation of a list, very fast for inserting, indexing, and moving the internal nodes of a list</li>
<li><strong><a href="http://pandas.pydata.org/">pandas</a></strong>: Data frames (or tables) very fast analytics on the arrays.</li>
<li><strong><a href="http://www.pytables.org/moin">pytables</a></strong>: Fast structured hierarchical tables (like hdf5), especially good for out of core calculations and queries to large data.</li>
</ul>


<h2>Scaling Python</h2>

<p>Right now there are a few distributed Python tools but the list is growing rapidly.  Here I just give a list the tools and some domain tools that are used in HPC that provide a Python interface.</p>

<h3>Distributed computing libraries</h3>

<ul>
<li><strong><a href="http://mpi4py.scipy.org/">mpi4py</a></strong>: Fastest most complete mpi Python wrapper.</li>
<li><strong><a href="http://discoproject.org/">disco</a></strong>: Python Hadoop-like framework.</li>
<li><strong><a href="http://ipython.org/ipython-doc/dev/parallel/index.html">IPython Parallel</a></strong>: A mpi or zero-mq based parallel Python.</li>
<li><strong><a href="http://dev.danse.us/trac/pathos">pathos</a></strong>: Framework for heterogeneous computing</li>
<li><strong><a href="http://www.emsl.pnl.gov/docs/global/">Global Arrays</a></strong>: A shared memory interface to distributed computing</li>
</ul>


<h3>Domain specific libraries</h3>

<ul>
<li><strong><a href="http://code.google.com/p/petsc4py/">petsc4py</a></strong>: Python bindings for PETSc, the Portable, Extensible Toolkit for Scientific Computation.</li>
<li><strong><a href="http://slepc4py.googlecode.com/">slepc4py</a></strong>: Python bindings for SLEPc, the Scalable Library for Eigenvalue Problem Computations.</li>
<li><strong><a href="http://tao4py.googlecode.com/">tao4py</a></strong>: Python bindings for TAO, the Toolkit for Advanced Optimization.</li>
<li><strong><a href="http://trilinos.sandia.gov/packages/pytrilinos/">pyTrilinos</a></strong>: Trilinos wrappers</li>
</ul>


<hr />

<h3>Changelog</h3>

<p>2012-09-27 Andy R. Terrel</p>

<pre><code>* Initial version
</code></pre>

<p>2012-09-30 Andy R. Terrel</p>

<pre><code>* Added links to Fernando Perez's 2008 version of this document
* Added link to Anaconda Pro
* Added link to Gael Varoquaux's scipy lectures
* Added link to Jeff Daily's Global Array Python bindings
* Added link to FWrap and f2py
* Fixed some grammatical mistakes
</code></pre>
]]></content>
  </entry>
  
</feed>
